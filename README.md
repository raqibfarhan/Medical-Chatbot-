 ğŸ©º MediBot â€“ AI-Powered Medical Chatbot

**MediBot** is an interactive medical chatbot powered by **Large Language Models (LLMs)**, **LangChain**, and **FAISS**.
It allows users to ask medical questions and get context-aware, accurate responses with traceable sources extracted from a trusted medical encyclopedia.

The application is built with a user-friendly **Streamlit interface**, uses **Groq-hosted Mistral or HuggingFace models**, and retrieves relevant document chunks using semantic vector search.

---
# âœ¨ Features

- ğŸ” **Semantic Search** using FAISS and SentenceTransformers
- ğŸ¤– **LLM-Powered Answers** (Groq-hosted LLaMA or HuggingFace Mistral)
- ğŸ“„ **Contextual QA** from embedded medical PDFs
- ğŸ“š **Source Document Tracing** in responses
- ğŸ’¬ **Chat Interface** built with Streamlit
- âš¡ **Cached Vector Store** for fast response time

---

# ğŸ§  How It Works

## ğŸ”§ `create_memory_for_llm.py`
- Loads medical PDFs from the `data/` directory
- Splits text into chunks using `RecursiveCharacterTextSplitter`
- Converts chunks into embeddings via `sentence-transformers/all-MiniLM-L6-v2`
- Stores embeddings locally in a **FAISS** vector database

## ğŸ”— `connect_memory_with_llm.py`
- Loads the FAISS vector store
- Defines a custom prompt template for controlled responses
- Connects to **Mistral-7B** hosted on HuggingFace
- Executes a single QA inference from the command line

## ğŸ–¥ï¸ `medibot.py`
- Runs a **Streamlit** web app
- Supports conversational chat with persistent session state
- Queries Groq-hosted LLaMA or any LLM via HuggingFace
- Displays answers and their source documents cleanly


## ğŸ›  Tools and Technologies Used

| Tool/Library      | Description |
|------------------|-------------|
| **LangChain**     | Framework for building LLM applications |
| **FAISS**         | Facebook AI Similarity Search â€“ Vector database |
| **Mistral 7B**    | Lightweight LLM used via HuggingFace or Groq |
| **HuggingFace**   | ML/LLM model hub |
| **Groq API**      | Ultra-fast inference API for open-source models |
| **Python**        | Primary programming language |
| **Streamlit**     | UI framework for interactive web apps |
| **VS Code**       | Development environment |
| **dotenv**        | For environment variable management |

---

## ğŸš€ Getting Started
pip install -r requirements.txt
3. Add API Keys
Create a .env file in the root directory:

GROQ_API_KEY=your_groq_api_key
HF_TOKEN=your_huggingface_token  # Optional if using HuggingFace

4. Prepare the Vectorstore

python create_memory_for_llm.py

5. Run the Chatbot UI
streamlit run medibot.py
ğŸ’¬ Example Output
User Prompt:

How to cure cancer?
Response:
The best chance for a surgical cure is usually with the first operation...
Source Docs:

[Document(metadata={'source': 'data/The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'page': 26}, ...)]
ğŸ“Œ To-Do List
 File upload for custom documents

 Source highlighting in document text

 Result formatting improvements

 Deployment on Streamlit Cloud or HuggingFace Spaces

ğŸ§‘â€ğŸ’» Author
Abdu Raqib Hidayathulla
LinkedIn - https://www.linkedin.com/in/abdu-raqib-hidayathulla-6b8664244/ 
Email- abduraqibfarhan@gmail.com

